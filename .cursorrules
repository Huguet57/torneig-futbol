# Instructions

During you interaction with the user, if you find anything reusable in this project (e.g. version of a library, model name), especially about a fix to a mistake you made or a correction you received, you should take note in the `Lessons` section in the `.cursorrules` file so you will not make the same mistake again.

You should also use the `.cursorrules` file as a scratchpad to organize your thoughts. Especially when you receive a new task, you should first review the content of the scratchpad, clear old different task if necessary, first explain the task, and plan the steps you need to take to complete the task. You can use todo markers to indicate the progress, e.g.
[X] Task 1
[ ] Task 2

Also update the progress of the task in the Scratchpad when you finish a subtask.
Especially when you finished a milestone, it will help to improve your depth of task accomplishment to use the scratchpad to reflect and plan.
The goal is to help you maintain a big picture as well as the progress of the task. Always refer to the Scratchpad when you plan the next step.

# Lessons

## User Specified Lessons

- Use poetry to run tests or anything python related.
- Include info useful for debugging in the program output.
- Read the file before you try to edit it.
- Use Ruff for linting and formatting Python code as it's faster and more comprehensive than flake8/black
- Set up pre-commit hooks to ensure code quality before committing changes
- Create shell scripts for common development tasks to improve workflow efficiency
- Document code quality practices in a separate file for better onboarding
- Address linting issues incrementally, starting with auto-fixable ones
- Pay attention to SQLAlchemy and Pydantic deprecation warnings to future-proof the codebase
- The simpler the implementation, the better
- Always develop a module and add the tests just after. Don't add several modules that can be filled with errors
- When implementing API endpoints, ensure all URLs have trailing slashes for consistency
- When creating new API endpoints, make sure to update the main.py file to include the new router
- Strive for simplicity first - implement only what's necessary and avoid feature creep

## Cursor learned

- For search results, ensure proper handling of different character encodings (UTF-8) for international queries
- Add debug information to stderr while keeping the main output clean in stdout for better pipeline integration
- When running tests, make sure PYTHONPATH includes the source directory to resolve imports correctly
- Even with correct poetry package configuration (packages = [{include = "package", from="src"}]), tests may need PYTHONPATH to include the project root to find the package
- When creating architectural plans, always include testing strategy and iterative development approach with feedback cycles
- Break down large documentation into separate files for better organization and easier reference
- In SQLAlchemy, joinedload is imported from sqlalchemy.orm and not a method of the Session object. Always import it separately: from sqlalchemy.orm import joinedload
- When writing APIs that return related objects, use joinedload to eagerly load relationships to avoid N+1 query issues and ensure related objects are included in responses
- When writing test scripts for API endpoints, make sure to use the correct API routes with proper prefixes (e.g., '/api/tournaments/' instead of '/tournaments/')
- Include status checks in test scripts to ensure proper error handling and debugging
- When implementing new features, ensure all required API endpoints are created and properly registered in the main application
- When creating schemas that require relationships, make sure to include the foreign key fields in both the model and schema
- When designing API endpoints that retrieve or create resources with optional filtering, ensure all possible filter combinations are handled correctly (e.g., optional tournament_id in player statistics)
- For statistics calculation functionality, always ensure proper update triggers are in place when related data changes, and include explicit update methods that can be called when needed
- When fixing database-related issues, check if the necessary database tables exist and consider using Base.metadata.create_all(bind=engine) to create tables directly from models
- Always verify that auxiliary methods required by core functionality are implemented (such as get_all_by_fields in the Match CRUD module)
- When running a FastAPI server, make sure to kill previous instances before starting a new one to avoid "Address already in use" errors
- When converting script-based tests to pytest, ensure field names in assertions match the actual schema field names (e.g., 'goals_scored' vs 'goals')
- In FastAPI projects with direct CRUD implementations in API files, make sure to import and use those implementations correctly in other modules
- When a CRUD module is referenced but doesn't exist (e.g., crud.tournament), check if it's implemented directly in the API file and import it from there
- Always check the schema definitions to understand the expected field names and structure when writing tests
- Use pytest markers to organize tests by functionality for easier selective test execution
- Ensure proper pytest configuration with conftest.py and pytest.ini for consistent test behavior
- For Pydantic V2+ models, use the newer model_config = {"from_attributes": True} syntax instead of the class Config approach
- Replace deprecated orm_mode = True with from_attributes = True in Pydantic models to avoid deprecation warnings
- Keep configuration styles consistent across all Pydantic models to avoid confusing warnings

# Scratchpad

## Soccer Tournament Management System

Previous task: Implementing MVP 1 - Tournament and Team Structure ✅
Previous task: Implementing MVP 2 - Match Management ✅
Current task: Implementing MVP 3 - Player Statistics ✅
Current task: Converting script tests to pytest tests ✅

[X] Set up project structure
  [X] Create directory structure
  [X] Configure Poetry dependencies
  [X] Set up Ruff linting

[X] Set up database models
  [X] Create base database configuration
  [X] Implement Tournament model
  [X] Implement Team model
  [X] Implement Phase model
  [X] Implement Group model
  [X] Implement Player model (basic)
  [X] Implement Match model (basic)

[X] Create API endpoints for MVP 1
  [X] Create base CRUD operations class
  [X] Implement Tournament endpoints
  [X] Implement Team endpoints
  [X] Implement Phase endpoints
  [X] Implement Group endpoints with team assignment

[X] Add unit tests for MVP 1
  [X] Set up test configuration
  [X] Create test fixtures
  [X] Test Tournament API endpoints
  [X] Test Team API endpoints
  [X] Test Group-Team relationships
  [X] Fix failing tests in group-team relationship

[X] Database migrations
  [X] Create Alembic configuration
  [X] Set up migration environment

[X] Add simple UI for MVP 1
  [X] Create base templates
  [X] Implement tournament management UI
  [X] Add CSS styling

[X] MVP 2: Match Management
  [X] Create match schemas
    [X] Create Match schema with validation
    [X] Create MatchCreate and MatchUpdate schemas
    [X] Add match result schema
  [X] Implement Match API endpoints
    [X] Create match CRUD operations
    [X] Implement match listing endpoints (by tournament, phase, group)
    [X] Add endpoint for updating match results
  [X] Implement Team Standing model/schema
    [X] Create standing model for storing group standings
    [X] Implement logic for calculating standings
    [X] Create API endpoints for retrieving standings
  [X] Add unit tests for match functionality
    [X] Test match CRUD operations
    [X] Test match listing by relationship (tournament, phase, group)
    [X] Test standings calculation
    [X] Test match result updates
  [X] Create Match UI
    [X] Implement match listing view
    [X] Add match creation form
    [X] Create match detail view with result updates

[X] Documentation
  [X] Update API endpoint documentation with match details
  [X] Create detailed match management documentation
  [X] Update README with project status

[X] Test the complete match management workflow
  [X] Verify match creation and listing
  [X] Test match result updates and standings calculation
  [X] Validate UI functionality for match management
  [X] Create and run end-to-end test script

[X] MVP 3: Player Statistics
  [X] Create Goal model and schemas
    [X] Implement Goal database model
    [X] Create Goal schemas with validation
    [X] Add API endpoints for managing goals
    [X] Create database migration for Goal model
    [X] Create test script for goal tracking
    [X] Update API documentation with goal endpoints
    [X] Implement Player API for player management
    [X] Test goal tracking functionality ← Completed!
  [X] Implement Player Statistics tracking
    [X] Create PlayerStats model and schema
    [X] Implement statistics calculation logic
    [X] Add API endpoints for player statistics
    [X] Test player statistics functionality ← Completed!
  [X] Implement Team Statistics
    [X] Enhance TeamStanding model for more detailed stats
    [X] Create aggregate tournament team statistics
    [X] Add API endpoints for team statistics
    [X] Fix issues with team statistics calculation
    [X] Add database migration for team stats
  [X] Develop unit and integration tests
    [X] Test player statistics calculations ← Completed!
    [X] Test team statistics calculations ← Completed!
  [X] Add documentation
    [X] Update API documentation with player statistics endpoints
    [X] Update API documentation with team statistics endpoints
    [X] Update README with new features

[X] Convert script tests to pytest tests
  [X] Create pytest test files
    [X] Create test_match_workflow.py
    [X] Create test_goal_tracking.py
    [X] Create test_player_stats.py
    [X] Create test_team_stats.py
  [X] Set up pytest configuration
    [X] Create conftest.py with test markers
    [X] Create pytest.ini with standard settings
  [X] Update README with pytest instructions
  [X] Fix test failures
    [X] Fix goal validation test
    [X] Fix player_stats API issues
    [X] Update field names in test assertions
  [X] Verify all tests pass
    [X] Run all tests
    [X] Run tests with markers
    [X] Check test coverage
  [X] Fix test warnings
    [X] Update Pydantic models to use newer configuration style
    [X] Replace deprecated orm_mode with from_attributes

Next: MVP 4 Planning:
The Soccer Tournament Management System has now successfully completed MVP 3, with all functionality for tracking player and team statistics working correctly. The test suite has been converted from script-based tests to pytest, providing better organization, isolation, and reporting.

Key accomplishments:
1. Implemented Goal model for tracking goals scored in matches
2. Created PlayerStats system to track player performance metrics
3. Enhanced team statistics with detailed performance metrics
4. Implemented API endpoints for retrieving and updating statistics
5. Developed comprehensive test suite with pytest
6. Fixed database and endpoint issues for reliable operation
7. Eliminated test warnings by updating Pydantic models to use the latest configuration patterns

Lessons learned during implementation:
- Always verify database tables exist before testing new functionality
- Ensure auxiliary methods required by core functionality are implemented
- Check for proper imports and dependencies between modules
- Validate that related database models are connected correctly
- Kill previous server instances before starting a new one to avoid "Address already in use" errors
- Use pytest markers to organize tests by functionality
- Ensure field names in test assertions match the actual schema field names
- Keep Pydantic model configurations consistent and up-to-date with the latest version

Next steps for MVP 4 - Advanced Features:
[ ] Phase progression rules
[ ] Tournament templates
[ ] Automatic scheduling
[ ] Improved UI/UX
[ ] Complete test coverage