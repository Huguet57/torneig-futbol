# Instructions

During you interaction with the user, if you find anything reusable in this project (e.g. version of a library, model name), especially about a fix to a mistake you made or a correction you received, you should take note in the `Lessons` section in the `.cursorrules` file so you will not make the same mistake again.

You should also use the `.cursorrules` file as a scratchpad to organize your thoughts. Especially when you receive a new task, you should first review the content of the scratchpad, clear old different task if necessary, first explain the task, and plan the steps you need to take to complete the task. You can use todo markers to indicate the progress, e.g.
[X] Task 1
[ ] Task 2

Also update the progress of the task in the Scratchpad when you finish a subtask.
Especially when you finished a milestone, it will help to improve your depth of task accomplishment to use the scratchpad to reflect and plan.
The goal is to help you maintain a big picture as well as the progress of the task. Always refer to the Scratchpad when you plan the next step.

# Lessons

## User Specified Lessons

- Use poetry to run tests or anything python related.
- Include info useful for debugging in the program output.
- Read the file before you try to edit it.
- Use Ruff for linting and formatting Python code as it's faster and more comprehensive than flake8/black
- Set up pre-commit hooks to ensure code quality before committing changes
- Create shell scripts for common development tasks to improve workflow efficiency
- Document code quality practices in a separate file for better onboarding
- Address linting issues incrementally, starting with auto-fixable ones
- Pay attention to SQLAlchemy and Pydantic deprecation warnings to future-proof the codebase
- The simpler the implementation, the better
- Always develop a module and add the tests just after. Don't add several modules that can be filled with errors
- When implementing API endpoints, ensure all URLs have trailing slashes for consistency
- When creating new API endpoints, make sure to update the main.py file to include the new router
- Strive for simplicity first - implement only what's necessary and avoid feature creep

## Cursor learned

- For search results, ensure proper handling of different character encodings (UTF-8) for international queries
- Add debug information to stderr while keeping the main output clean in stdout for better pipeline integration
- When running tests, make sure PYTHONPATH includes the source directory to resolve imports correctly
- Even with correct poetry package configuration (packages = [{include = "package", from="src"}]), tests may need PYTHONPATH to include the project root to find the package
- When creating architectural plans, always include testing strategy and iterative development approach with feedback cycles
- Break down large documentation into separate files for better organization and easier reference
- In SQLAlchemy, joinedload is imported from sqlalchemy.orm and not a method of the Session object. Always import it separately: from sqlalchemy.orm import joinedload
- When writing APIs that return related objects, use joinedload to eagerly load relationships to avoid N+1 query issues and ensure related objects are included in responses
- When writing test scripts for API endpoints, make sure to use the correct API routes with proper prefixes (e.g., '/api/tournaments/' instead of '/tournaments/')
- Include status checks in test scripts to ensure proper error handling and debugging
- When implementing new features, ensure all required API endpoints are created and properly registered in the main application
- When creating schemas that require relationships, make sure to include the foreign key fields in both the model and schema
- When designing API endpoints that retrieve or create resources with optional filtering, ensure all possible filter combinations are handled correctly (e.g., optional tournament_id in player statistics)
- For statistics calculation functionality, always ensure proper update triggers are in place when related data changes, and include explicit update methods that can be called when needed
- When fixing database-related issues, check if the necessary database tables exist and consider using Base.metadata.create_all(bind=engine) to create tables directly from models
- Always verify that auxiliary methods required by core functionality are implemented (such as get_all_by_fields in the Match CRUD module)
- When running a FastAPI server, make sure to kill previous instances before starting a new one to avoid "Address already in use" errors
- When converting script-based tests to pytest, ensure field names in assertions match the actual schema field names (e.g., 'goals_scored' vs 'goals')
- In FastAPI projects with direct CRUD implementations in API files, make sure to import and use those implementations correctly in other modules
- When a CRUD module is referenced but doesn't exist (e.g., crud.tournament), check if it's implemented directly in the API file and import it from there
- Always check the schema definitions to understand the expected field names and structure when writing tests
- Use pytest markers to organize tests by functionality for easier selective test execution
- Ensure proper pytest configuration with conftest.py and pytest.ini for consistent test behavior
- For Pydantic V2+ models, use the newer model_config = {"from_attributes": True} syntax instead of the class Config approach
- Replace deprecated orm_mode = True with from_attributes = True in Pydantic models to avoid deprecation warnings
- Keep configuration styles consistent across all Pydantic models to avoid confusing warnings

# Scratchpad

## Soccer Tournament Management System

### Current Status
- Completed: MVP 1 - Tournament and Team Structure âœ…
- Completed: MVP 2 - Match Management âœ… 
- Completed: MVP 3 - Player Statistics âœ…
- Completed: Converting script tests to pytest tests âœ…
- Current: MVP 4 - Backend Quality & Scalability ðŸ”„

### Completed MVPs Summary

MVP 1-3 implemented the following core functionality:
- Tournament, team, phase, and group management
- Match scheduling and result tracking
- Team standings calculation
- Goal tracking with player attribution
- Player statistics (goals, matches played, etc.)
- Team statistics with performance metrics
- Complete test coverage of core features
- Comprehensive API documentation

Key accomplishments:
1. Implemented Goal model for tracking goals scored in matches
2. Created PlayerStats system to track player performance metrics
3. Enhanced team statistics with detailed performance metrics
4. Implemented API endpoints for retrieving and updating statistics
5. Developed comprehensive test suite with pytest
6. Fixed database and endpoint issues for reliable operation
7. Eliminated test warnings by updating Pydantic models to use the latest configuration patterns

Lessons learned during implementation:
- Always verify database tables exist before testing new functionality
- Ensure auxiliary methods required by core functionality are implemented
- Check for proper imports and dependencies between modules
- Validate that related database models are connected correctly
- Kill previous server instances before starting a new one to avoid "Address already in use" errors
- Use pytest markers to organize tests by functionality
- Ensure field names in test assertions match the actual schema field names
- Keep Pydantic model configurations consistent and up-to-date with the latest version

### MVP 4 Planning - Backend Quality & Scalability

[X] Review completed features and system architecture
[ ] Comprehensive Test Suite Enhancement
  [ ] Improve unit test coverage
    [ ] Identify modules with <90% coverage
    [ ] Add tests for untested edge cases and error conditions
    [ ] Improve assertion quality and error messages
  [ ] Add integration tests
    [ ] Create end-to-end workflow tests
    [ ] Test database transaction integrity
    [ ] Test concurrent API access patterns
  [ ] Implement performance benchmarks
    [ ] Establish baseline performance metrics
    [ ] Create test fixtures for large datasets
    [ ] Implement load testing scripts
  [ ] Set up continuous integration
    [ ] Configure GitHub Actions workflow
    [ ] Implement automated test runs with reports
    [ ] Add code quality checks to CI pipeline

[ ] Code Refactoring for Maintainability
  [ ] Standardize API implementation patterns
    [ ] Review and align CRUD operation implementations
    [ ] Extract common patterns into reusable utility functions
    [ ] Ensure consistent error handling across endpoints
  [ ] Improve database access layer
    [ ] Optimize database queries with proper indexing
    [ ] Add query result caching for frequently accessed data
    [ ] Ensure proper transaction management
  [ ] Enhance type safety
    [ ] Add comprehensive type hints throughout codebase
    [ ] Implement runtime type validation for critical functions
    [ ] Configure mypy for static type checking
  [ ] Reduce code duplication
    [ ] Extract common functionality into shared modules
    [ ] Create reusable service components
    [ ] Implement consistent dependency injection

[ ] Database and ORM Optimization
  [ ] Audit and optimize database schema
    [ ] Add missing indexes for frequent query patterns
    [ ] Review and optimize relationship definitions
    [ ] Add database-level constraints for data integrity
  [ ] Implement connection pooling
    [ ] Configure optimal pool size based on workload
    [ ] Add connection lifecycle monitoring
    [ ] Implement connection retry logic
  [ ] Optimize SQLAlchemy usage
    [ ] Review and optimize query generation
    [ ] Add eager loading strategies for related objects
    [ ] Implement proper session management patterns
  [ ] Add database migration testing
    [ ] Create test scripts for verifying migrations
    [ ] Ensure backward compatibility in schema changes
    [ ] Add validation for data integrity during migrations

[ ] API Performance Optimization
  [ ] Implement proper pagination
    [ ] Add cursor-based pagination for large collections
    [ ] Optimize count queries for pagination metadata
    [ ] Add client-side caching headers
  [ ] Add request validation and throttling
    [ ] Implement rate limiting for API endpoints
    [ ] Add input validation with helpful error messages
    [ ] Protect against common attack patterns
  [ ] Optimize data serialization
    [ ] Benchmark and optimize JSON serialization
    [ ] Add response compression
    [ ] Implement partial response patterns for large resources
  [ ] Create performance monitoring
    [ ] Add request timing metrics
    [ ] Track database query performance
    [ ] Create dashboard for API performance

[ ] Documentation and Developer Experience
  [ ] Enhance API documentation
    [ ] Update OpenAPI/Swagger docs with detailed examples
    [ ] Document error responses and recovery strategies
    [ ] Create Postman collection for API testing
  [ ] Improve code documentation
    [ ] Add docstrings to all modules and functions
    [ ] Create architecture documentation with diagrams
    [ ] Document design decisions and trade-offs
  [ ] Streamline developer onboarding
    [ ] Improve README with clear setup instructions
    [ ] Create development environment setup script
    [ ] Document common development workflows
  [ ] Add observability tools
    [ ] Implement structured logging
    [ ] Add error tracking and reporting
    [ ] Create health check endpoints

### MVP 4 Development Approach

For MVP 4, we'll follow these development principles:
1. **Measure first**: Establish metrics and benchmarks before making improvements
2. **Iterative enhancement**: Focus on one area at a time with clear before/after measurements
3. **Test-driven refactoring**: Add tests before refactoring code to ensure behavior doesn't change
4. **Documentation**: Update documentation alongside code changes to maintain alignment
5. **Technical debt reduction**: Prioritize issues that will create long-term maintenance benefits

Weekly milestones:
- Week 1: Test suite enhancement and coverage improvement
- Week 2: Code refactoring for maintainability
- Week 3: Database and ORM optimization
- Week 4: API performance optimization
- Week 5: Documentation and developer experience improvements
- Week 6: Final review, benchmarking, and planning for future development